## 确定执行的优先级

在优化一个学习算法时，我们通常有多种思想来改进算法，但是哪种方法是最优的却需要一种标准来评判。

### 误差分析

在判断优化方法时，我们最常用的方式是先计算出没有使用该优化方式的错误率，再计算出使用了该方式的算法错误率，通过比较两者，从而达到了选择优化策略的目的。

### 不对称性的误差分析

我们上面的算法误差分析是通过错误率(正确率)来判断误差的，但是对于偏斜类问题，单独使用正确率来判断往往是不准确的。

#### 偏斜问题

在癌症预测的问题中，我们使用肿瘤的大小来判断是否罹患癌症，假设我们设计的算法的准确率达到了$99\%$，这似乎听起来是一个很好的模型，准确率很高，但是数据集中罹患癌症的数量只占据的$0.5\%$，这意味着如果我们不使用机器学习算法，只单纯的认为所有人都没有得癌症，那么我们算法的准确率在$0.5\%$，这似乎还要优于我们的机器学习算法，但是现实经验告诉我们这实际上不是一个高性能的算法，像这类数据集比例极不均衡(患有癌症的人数远远小于健康的人)的问题被称为偏斜问题。

#### 精准度/召回率

为了解决偏斜问题，我们提出了精准度和召回率两个概念来共同评估算法的优劣。

在癌症预测问题中，我们定义$2\times2$表格：

![](http://oss.pyaxy.xyz/img/37.png)

其中左上表示我们预测为真且实际真为患者的数量，称为真阳性。

右下表示我们预测为健康且实际真为健康的数量，称为真阴性。

右上表示我们预测为患者但是实际为健康的数量，称为假阳性。

左下表示我们预测为健康但是实际为患者的数量，称为假阴性。

我们定义**准确率**(precision)：
$$
\frac{真阳性的数量}{算法预测的阳性的数量}
$$
定义**召回率**(recall):
$$
\frac{真阳性的数量}{样本中所有阳性的数量}
$$
在我们上面认为所有患者均为健康的算法中，召回率显然为$0$，因此说明这不是一个很好的算法。

如果一个算法有着较高的准确率以及较高的召回率，我们就可以认为这是一个比较良好的算法。

### 精准度和召回率的权衡

在我们的癌症预测问题中，我们使用了逻辑回归，判断癌症的临界值设为$h_\theta(x)>0.5$，但是鉴于判断癌症是一个较为严肃的问题，基于现实经验，一旦下结论就可能对患者的心理造成冲击，因此我们采用一个比较高的临界值来判断：$h_\theta(X)>0.7$

我们使用了较大的临界值会使我们的预测更谨慎，我们的准确率会上升，但是我们的召回率会下降。

鉴于如果罹患癌症却被诊断为健康导致没有得到及时治疗从而死亡的后果较为严重，我们需要降低临界值，从而提高了召回率，但是我们的准确率下降了，因为随着判断的阳性数量变多肯定会有更多的人是健康的。



上面的问题说明了我们在召回率和准确率之间是需要一个权衡的，而不是像单纯的误差分析那样只通过数值来判断。因此我们引入$F_1值$：
$$
F_1=2\times\frac{precision\times recall}{precision+recall}
$$
我们在实际中通常对一系列临界值进行训练再计算出$F_1$，通过判断$F_1$的大小可以很好的得出临界值的选择。

### 机器学习的数据

在机器学习中，往往更多的数据可以带来性能更好的算法。

一个良好的算法通常有很多高阶特征同时又有极大的数据来进行训练从而防止过拟合的问题。## 确定执行的优先级

在优化一个学习算法时，我们通常有多种思想来改进算法，但是哪种方法是最优的却需要一种标准来评判。

### 误差分析

在判断优化方法时，我们最常用的方式是先计算出没有使用该优化方式的错误率，再计算出使用了该方式的算法错误率，通过比较两者，从而达到了选择优化策略的目的。

### 不对称性的误差分析

我们上面的算法误差分析是通过错误率(正确率)来判断误差的，但是对于偏斜类问题，单独使用正确率来判断往往是不准确的。

#### 偏斜问题

在癌症预测的问题中，我们使用肿瘤的大小来判断是否罹患癌症，假设我们设计的算法的准确率达到了$99\%$，这似乎听起来是一个很好的模型，准确率很高，但是数据集中罹患癌症的数量只占据的$0.5\%$，这意味着如果我们不使用机器学习算法，只单纯的认为所有人都没有得癌症，那么我们算法的准确率在$0.5\%$，这似乎还要优于我们的机器学习算法，但是现实经验告诉我们这实际上不是一个高性能的算法，像这类数据集比例极不均衡(患有癌症的人数远远小于健康的人)的问题被称为偏斜问题。

#### 精准度/召回率

为了解决偏斜问题，我们提出了精准度和召回率两个概念来共同评估算法的优劣。

在癌症预测问题中，我们定义$2\times2$表格：

![](http://oss.pyaxy.xyz/img/37.png)

其中左上表示我们预测为真且实际真为患者的数量，称为真阳性。

右下表示我们预测为健康且实际真为健康的数量，称为真阴性。

右上表示我们预测为患者但是实际为健康的数量，称为假阳性。

左下表示我们预测为健康但是实际为患者的数量，称为假阴性。

我们定义**准确率**(precision)：
$$
\frac{真阳性的数量}{算法预测的阳性的数量}
$$
定义**召回率**(recall):
$$
\frac{真阳性的数量}{样本中所有阳性的数量}
$$
在我们上面认为所有患者均为健康的算法中，召回率显然为$0$，因此说明这不是一个很好的算法。

如果一个算法有着较高的准确率以及较高的召回率，我们就可以认为这是一个比较良好的算法。

### 精准度和召回率的权衡

在我们的癌症预测问题中，我们使用了逻辑回归，判断癌症的临界值设为$h_\theta(x)>0.5$，但是鉴于判断癌症是一个较为严肃的问题，基于现实经验，一旦下结论就可能对患者的心理造成冲击，因此我们采用一个比较高的临界值来判断：$h_\theta(X)>0.7$

我们使用了较大的临界值会使我们的预测更谨慎，我们的准确率会上升，但是我们的召回率会下降。

鉴于如果罹患癌症却被诊断为健康导致没有得到及时治疗从而死亡的后果较为严重，我们需要降低临界值，从而提高了召回率，但是我们的准确率下降了，因为随着判断的阳性数量变多肯定会有更多的人是健康的。



上面的问题说明了我们在召回率和准确率之间是需要一个权衡的，而不是像单纯的误差分析那样只通过数值来判断。因此我们引入$F_1值$：
$$
F_1=2\times\frac{precision\times recall}{precision+recall}
$$
我们在实际中通常对一系列临界值进行训练再计算出$F_1$，通过判断$F_1$的大小可以很好的得出临界值的选择。

### 机器学习的数据

在机器学习中，往往更多的数据可以带来性能更好的算法。

一个良好的算法通常有很多高阶特征同时又有极大的数据来进行训练从而防止过拟合的问题。