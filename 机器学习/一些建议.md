## 一些建议

我们在设计机器学习模型的过程中，会遇到许多问题，比如训练集的大小的选择，特征数量的选择，模型多项式的选择，正则化参数$\lambda$的大小选择等，下面介绍如何解决上面的问题，以及遇到什么情况了我们该增大或减小哪个参数的问题

### 评估模型

在我们训练模型的过程中，我们通常会遇到过拟合的问题，为了判断一个模型的泛化性，我们将数据集按$7:3$分割，其中$70\%$用于训练模型，剩下的用于测试模型的泛化性。

比如在线性回归中，我们用$70\%$的训练集拟合出了$\theta$，然后将$\theta$带入$J(\theta)$，且使用测试集中的数据来计算出误差，以此来评估模型

### 模型的选择

在我们选择一个模型时，我们需要选择多项式的次数，假设次数为$d$，我们需要选择$d$。

我们现在把训练集分为三个部分，第一部分为训练集，第二部分为交叉验证($cross$ $validation$)集，第三部分为测试集，分配比例为$6:2:2$。

接下来我们对每一次方的模型都拟合出一个$\theta$出来，然后用验证集来计算出代价函数，选择出最小的值对应的次方。

### 偏差与方差

在我们选择模型之后，我们可能仍然不能很好的拟合出正确的模型，我们的代价函数依然很大，这时我们需要判断此时的模型状态是方差问题还是偏差问题。

![](http://oss.pyaxy.xyz/img/30.png)

如图，在我们的多项式次数较低的时候，我们的模型会出现欠拟合，这时无论对训练集的代价函数还是验证集的代价函数，对应的误差都比较高，**这时我们认为这是我们对模型的偏差较大**；当多项式次数较高的时候，我们的模型出现过拟合，这时我们的训练集能很好的满足模型的预测，但是验证集的代价函数的值还是较高，**这时我们认为模型的方差较大**，此时验证集的代价函数远大于训练集的代价函数。

### 正则化与方差、偏差

在我们防止过拟合的过程中，我们会在代价函数后面添加一个正则化项。

当我们的正则化参数$\lambda$较大时：

![](http://oss.pyaxy.xyz/img/31.png)

会出现欠拟合的情况，较大的$\lambda$会对$\theta$造成过大的惩罚，使其值接近于零。

当$\lambda$较小时：

![](http://oss.pyaxy.xyz/img/32.png)

会出现过拟合的情况，较小的$\lambda$会对$\theta$几乎没有惩罚，相当于没有进行正则化。



我们定义训练集、验证集、测试集的代价函数都不带有正则化项。

在选择正则化参数时，尝试从$\lambda=0,\ \lambda=0.01,\ \lambda = 0.02,\ \lambda = 0.04,\ ......,\ \lambda=10.24$一一训练模型，在$\lambda=0$时使用带有正则化的代价函数拟合出$\theta$再带入到验证集中计算出验证集的代价函数值，以此类推。最后得到最小的验证集代价函数对应的正则化参数。

下面用图来表示$\lambda$对代价函数的影响：

![](http://oss.pyaxy.xyz/img/33.png)

### 学习曲线

学习曲线是一个可以很好判断假设模型是否处于方差或偏差问题之中的工具。

当模型刚好时的学习曲线：

![](http://oss.pyaxy.xyz/img/34.png)

高偏差时的学习曲线：

![](http://oss.pyaxy.xyz/img/35.png)

当处于高偏差的状态时，使用更多的数据集往往不能帮助我们改进模型，因为多项式的阶数太低，无论有多少数据集都会发生欠拟合问题。

高方差时的学习曲线：

![](http://oss.pyaxy.xyz/img/36.png)

高方差时，当我们增加数据集时，我们的验证集的误差值会下降，所以对于高方差问题，增加训练集数量往往会有帮助。

### 总结

使用更多的训练集——高方差问题

减少特征的数量——高方差问题

增加特征的数量——高偏差问题

增加高阶特征——高偏差问题

减少$\lambda$——高偏差问题

增加$\lambda$——高方差问题## 一些建议

我们在设计机器学习模型的过程中，会遇到许多问题，比如训练集的大小的选择，特征数量的选择，模型多项式的选择，正则化参数$\lambda$的大小选择等，下面介绍如何解决上面的问题，以及遇到什么情况了我们该增大或减小哪个参数的问题

### 评估模型

在我们训练模型的过程中，我们通常会遇到过拟合的问题，为了判断一个模型的泛化性，我们将数据集按$7:3$分割，其中$70\%$用于训练模型，剩下的用于测试模型的泛化性。

比如在线性回归中，我们用$70\%$的训练集拟合出了$\theta$，然后将$\theta$带入$J(\theta)$，且使用测试集中的数据来计算出误差，以此来评估模型

### 模型的选择

在我们选择一个模型时，我们需要选择多项式的次数，假设次数为$d$，我们需要选择$d$。

我们现在把训练集分为三个部分，第一部分为训练集，第二部分为交叉验证($cross$ $validation$)集，第三部分为测试集，分配比例为$6:2:2$。

接下来我们对每一次方的模型都拟合出一个$\theta$出来，然后用验证集来计算出代价函数，选择出最小的值对应的次方。

### 偏差与方差

在我们选择模型之后，我们可能仍然不能很好的拟合出正确的模型，我们的代价函数依然很大，这时我们需要判断此时的模型状态是方差问题还是偏差问题。

![](http://oss.pyaxy.xyz/img/30.png)

如图，在我们的多项式次数较低的时候，我们的模型会出现欠拟合，这时无论对训练集的代价函数还是验证集的代价函数，对应的误差都比较高，**这时我们认为这是我们对模型的偏差较大**；当多项式次数较高的时候，我们的模型出现过拟合，这时我们的训练集能很好的满足模型的预测，但是验证集的代价函数的值还是较高，**这时我们认为模型的方差较大**，此时验证集的代价函数远大于训练集的代价函数。

### 正则化与方差、偏差

在我们防止过拟合的过程中，我们会在代价函数后面添加一个正则化项。

当我们的正则化参数$\lambda$较大时：

![](http://oss.pyaxy.xyz/img/31.png)

会出现欠拟合的情况，较大的$\lambda$会对$\theta$造成过大的惩罚，使其值接近于零。

当$\lambda$较小时：

![](http://oss.pyaxy.xyz/img/32.png)

会出现过拟合的情况，较小的$\lambda$会对$\theta$几乎没有惩罚，相当于没有进行正则化。



我们定义训练集、验证集、测试集的代价函数都不带有正则化项。

在选择正则化参数时，尝试从$\lambda=0,\ \lambda=0.01,\ \lambda = 0.02,\ \lambda = 0.04,\ ......,\ \lambda=10.24$一一训练模型，在$\lambda=0$时使用带有正则化的代价函数拟合出$\theta$再带入到验证集中计算出验证集的代价函数值，以此类推。最后得到最小的验证集代价函数对应的正则化参数。

下面用图来表示$\lambda$对代价函数的影响：

![](http://oss.pyaxy.xyz/img/33.png)

### 学习曲线

学习曲线是一个可以很好判断假设模型是否处于方差或偏差问题之中的工具。

当模型刚好时的学习曲线：

![](http://oss.pyaxy.xyz/img/34.png)

高偏差时的学习曲线：

![](http://oss.pyaxy.xyz/img/35.png)

当处于高偏差的状态时，使用更多的数据集往往不能帮助我们改进模型，因为多项式的阶数太低，无论有多少数据集都会发生欠拟合问题。

高方差时的学习曲线：

![](http://oss.pyaxy.xyz/img/36.png)

高方差时，当我们增加数据集时，我们的验证集的误差值会下降，所以对于高方差问题，增加训练集数量往往会有帮助。

### 总结

使用更多的训练集——高方差问题

减少特征的数量——高方差问题

增加特征的数量——高偏差问题

增加高阶特征——高偏差问题

减少$\lambda$——高偏差问题

增加$\lambda$——高方差问题